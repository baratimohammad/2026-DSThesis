{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb70fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca019bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "\n",
    "db_params = {\n",
    "    \"host\": os.getenv(\"POSTGRES_HOST\"),\n",
    "    \"port\": os.getenv(\"POSTGRES_PORT\"),\n",
    "    \"dbname\": os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "}\n",
    "if not all(db_params.values()):\n",
    "    print(\"Database connection parameters are not fully set in environment variables.\")\n",
    "    sys.exit(1)\n",
    "DB_URL = f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['dbname']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d0c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing schemas in the db:\n",
      "\t core\n",
      "\t etl\n",
      "\t marts\n",
      "\t quarantine\n",
      "\t staging\n"
     ]
    }
   ],
   "source": [
    "with psycopg2.connect(DB_URL) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"select nspname from pg_namespace where nspname in ('etl','staging','core','marts','quarantine') order by 1;\")\n",
    "        schemas = cur.fetchall()\n",
    "        print(\"Existing schemas in the db:\")\n",
    "        for schema in schemas:\n",
    "            print('\\t',schema[0])\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c9378ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attivita_formative_esterne\n",
      "attivita_formative_fuorisede\n",
      "attivita_formative_interne\n",
      "collaborazioni_dettaglio\n",
      "corsi\n",
      "dettaglio_corso\n",
      "filtered_iu_stats\n",
      "journal_details\n",
      "mobilita_internazionale_con_studenti\n",
      "ore_formazione\n",
      "pubblicazioni\n",
      "stat_pubb\n",
      "students\n"
     ]
    }
   ],
   "source": [
    "with psycopg2.connect(DB_URL) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"select tablename from pg_tables where schemaname='staging' order by 1;\")\n",
    "        [print(x[0]) for x in cur.fetchall()]\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5497c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg2.connect(DB_URL) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"truncate table etl.schema_migrations;\")\n",
    "        # [print(x[0]) for x in cur.fetchall()]\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3944c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attivita_formative_esterne\n",
      "attivita_formative_fuorisede\n",
      "attivita_formative_interne\n",
      "collaborazioni_dettaglio\n",
      "corsi\n",
      "dettaglio_corso\n",
      "filtered_iu_stats\n",
      "journal_details\n",
      "mobilita_internazionale_con_studenti\n",
      "ore_formazione\n",
      "pubblicazioni\n",
      "stat_pubb\n",
      "students\n"
     ]
    }
   ],
   "source": [
    "with psycopg2.connect(DB_URL) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"select tablename from pg_tables where schemaname='staging' order by 1;\")\n",
    "        [print(x[0]) for x in cur.fetchall()]\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66917761",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg2.connect(DB_URL) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        # cur.execute(\n",
    "        #     \"SELECT * FROM etl.file_manifest ;\")\n",
    "        # print(cur.fetchall())\n",
    "\n",
    "        cur.execute(\"truncate table etl.runs cascade;\")\n",
    "        cur.execute(\"truncate table etl.file_manifest;\")\n",
    "        cur.execute(\"truncate table staging.students cascade;\")\n",
    "        cur.execute(\"truncate table staging.attivita_formative_esterne cascade;\")\n",
    "        cur.execute(\"truncate table staging.attivita_formative_fuorisede cascade;\")\n",
    "        cur.execute(\"truncate table staging.attivita_formative_interne cascade;\")\n",
    "        cur.execute(\"truncate table staging.corsi cascade;\")\n",
    "\n",
    "        cur.execute(\"truncate table staging.collaborazioni_dettaglio cascade;\")\n",
    "        cur.execute(\"truncate table staging.dettaglio_corso cascade;\")\n",
    "        cur.execute(\"truncate table staging.filtered_iu_stats cascade;\")\n",
    "        cur.execute(\"truncate table staging.journal_details cascade;\")\n",
    "        cur.execute(\"truncate table staging.mobilita_internazionale_con_studenti cascade;\")\n",
    "        cur.execute(\"truncate table staging.ore_formazione cascade;\")\n",
    "        cur.execute(\"truncate table staging.pubblicazioni cascade;\")\n",
    "        cur.execute(\"truncate table staging.stat_pubb cascade;\")\n",
    "        # cur.execute(\"truncate table etl.schema_migrations;\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cba3e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Run success: a6a44ef3-b3fc-4175-bdf1-df34bf15b9e3\n"
     ]
    }
   ],
   "source": [
    "from pipeline.staging_transforms import t_students\n",
    "from pipeline.staging_tools import create_run, load_one_file, finish_run\n",
    "import glob\n",
    "\n",
    "job = {\n",
    "        \"pattern\": \"./data/input/cicli/*/0_students_info.csv\",\n",
    "        \"table\": \"staging.students\",\n",
    "        \"transform\": t_students,\n",
    "    }\n",
    "\n",
    "\n",
    "with psycopg2.connect(DB_URL) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            run_id = create_run(cur)\n",
    "            conn.commit()\n",
    "            try:\n",
    "                files = sorted(glob.glob(job[\"pattern\"]))\n",
    "                for f in files:\n",
    "                    load_one_file(cur, run_id, f, job['table'], job['transform'])\n",
    "                    conn.commit()\n",
    "                finish_run(cur, run_id, \"SUCCESS\", None)\n",
    "                conn.commit()\n",
    "                print(f\"✅ Run success: {run_id}\")\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                finish_run(cur, run_id, \"FAILED\", str(e))\n",
    "                conn.commit()\n",
    "                print(f\"❌ Run failed: {run_id} | {e}\", file=sys.stderr)\n",
    "conn.close()\n",
    "                 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfaf23cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matricola</th>\n",
       "      <th>cognome</th>\n",
       "      <th>nome</th>\n",
       "      <th>numero_journal</th>\n",
       "      <th>numero_conferenze</th>\n",
       "      <th>numero_capitoli</th>\n",
       "      <th>numero_poster</th>\n",
       "      <th>numero_abstract</th>\n",
       "      <th>numero_brevetti</th>\n",
       "      <th>quartile_1</th>\n",
       "      <th>quartile_2</th>\n",
       "      <th>quartile_3</th>\n",
       "      <th>quartile_4</th>\n",
       "      <th>quartile_5</th>\n",
       "      <th>quartile_6</th>\n",
       "      <th>quartile_7</th>\n",
       "      <th>quartile_8</th>\n",
       "      <th>quartile_9</th>\n",
       "      <th>quartile_10</th>\n",
       "      <th>quartile_11</th>\n",
       "      <th>quartile_12</th>\n",
       "      <th>quartile_13</th>\n",
       "      <th>quartile_14</th>\n",
       "      <th>quartile_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59760</td>\n",
       "      <td>INSINGA</td>\n",
       "      <td>GIORGIO</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61952</td>\n",
       "      <td>DRI</td>\n",
       "      <td>EMANUELE</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16417</td>\n",
       "      <td>SISINNI</td>\n",
       "      <td>SILVIA</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33249</td>\n",
       "      <td>ROBBIANO</td>\n",
       "      <td>LUCA</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54130</td>\n",
       "      <td>ANGI</td>\n",
       "      <td>ANTONINO</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matricola   cognome      nome  ...  quartile_13  quartile_14  quartile_15\n",
       "0      59760   INSINGA   GIORGIO  ...          NaN          NaN          NaN\n",
       "1      61952       DRI  EMANUELE  ...          NaN          NaN          NaN\n",
       "2      16417   SISINNI    SILVIA  ...          NaN          NaN          NaN\n",
       "3      33249  ROBBIANO      LUCA  ...          NaN          NaN          NaN\n",
       "4      54130      ANGI  ANTONINO  ...          NaN          NaN          NaN\n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/input/stat_pubb/stat_pubb_37.csv\", delimiter=',')  \n",
    "# df = df[~(df['Teacher']=='Nessuna collaborazione prevista')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a96b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "37\n",
      "39\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "files = glob.glob('data/input/journal_details/journal_details_*.csv')\n",
    "for f in files:\n",
    "    base = os.path.basename(f)\n",
    "    m = re.match(r\"journal_details_(\\d+)\\.csv$\", base)\n",
    "    ciclo = m.group(1) if m else None\n",
    "    print(ciclo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ed7d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stage_attivita_interne() missing 2 required positional arguments: 'cur' and 'run_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m     98\u001b[39m             mark_manifest(\n\u001b[32m     99\u001b[39m                 cur,\n\u001b[32m    100\u001b[39m                 file_hash,\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m                 error_message=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    104\u001b[39m             )\n\u001b[32m    105\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[43mstage_attivita_interne\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# for f in glob.glob(\"./data/input/cicli/*/*_attivita_formative_interne.csv\"):\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m#     print(extract_matricola_from_filename(f))\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m#     print(extract_ciclo_from_path(f))\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: stage_attivita_interne() missing 2 required positional arguments: 'cur' and 'run_id'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pipeline.staging_tools import (extract_ciclo_from_path, extract_matricola_from_filename, extract_cod_ins_and_anno,\n",
    "                           copy_df_to_staging, is_empty_marker_file, mark_manifest, sha256_file,\n",
    "                           upsert_manifest)\n",
    "from typing import Mapping\n",
    "import psycopg2.extensions as conn\n",
    "import glob\n",
    "\n",
    "def stage_attivita_interne( # TO BE COMPLETED\n",
    "    cur: conn.cursor,\n",
    "    run_id: int,\n",
    "    file_path: str = \"./data/input/cicli/*/*_attivita_formative_insterne.csv\",\n",
    "    table: str = \"staging.attivita_formative_interne\",\n",
    ") -> None:\n",
    "\n",
    "    colmap: Mapping[str, str] = {\n",
    "    \"Cod Ins.\": \"cod_ins\",\n",
    "    \"Nome insegnamento\": \"nome_insegnamento\",\n",
    "    \"Ore\": \"ore\",\n",
    "    \"Ore riconosciute\": \"ore_riconosciute\",\n",
    "    \"Voto\": \"voto\",\n",
    "    \"Coeff. voto\": \"coeff_voto\",\n",
    "    \"Data esame\": \"data_esame\",\n",
    "    \"Tipo form.\": \"tipo_form\",\n",
    "    \"Liv. Esame\": \"liv_esame\",\n",
    "    \"Tipo attività\": \"tipo_attivita\",\n",
    "    \"Punti\": \"punti\",\n",
    "}\n",
    "\n",
    "    files = sorted(glob.glob(file_path))\n",
    "\n",
    "    for f in files:\n",
    "        file_hash = sha256_file(f)                      # compute file hash for etl.file_manifest\n",
    "        file_size = os.path.getsize(f)                  # compute file size for etl.file_manifest\n",
    "        matricola = extract_matricola_from_filename(f)\n",
    "        ciclo = extract_ciclo_from_path(f)\n",
    "\n",
    "        upsert_manifest(cur, run_id, f, file_hash, file_size, status=\"NEW\")\n",
    "\n",
    "        cur.execute(\n",
    "            \"SELECT status FROM etl.file_manifest WHERE file_hash_sha256=%s\",\n",
    "            (file_hash,),\n",
    "        )\n",
    "        existing_status = cur.fetchone()\n",
    "        if existing_status and existing_status[0] in (\"LOADED\", \"SKIPPED\"):\n",
    "            print(f\"File {f} already loaded with status {existing_status[0]}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Loading file {f} into {table}...\")\n",
    "        try:\n",
    "            if is_empty_marker_file(f):\n",
    "                mark_manifest(\n",
    "                    cur,\n",
    "                    file_hash,\n",
    "                    status=\"SKIPPED\",\n",
    "                    rows_loaded=0,\n",
    "                    error_message=\"Empty marker detected\",\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            raw = pd.read_csv(f, delimiter=\",\", dtype=str)\n",
    "            keep = [c for c in colmap if c in raw.columns]\n",
    "            df = raw[keep].rename(columns=colmap)\n",
    "\n",
    "            if df.empty:\n",
    "                mark_manifest(\n",
    "                    cur,\n",
    "                    file_hash,\n",
    "                    status=\"SKIPPED\",\n",
    "                    rows_loaded=0,\n",
    "                    error_message=\"No rows after transform\",\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            df.insert(0, \"run_id\", run_id)\n",
    "            df.insert(1, \"source_file\", f)\n",
    "            df.insert(2, \"loaded_at\", datetime.now(timezone.utc).isoformat())\n",
    "            df.insert(3, \"matricola\", matricola)\n",
    "            df.insert(4, \"ciclo\", ciclo)\n",
    "\n",
    "            copy_df_to_staging(cur, df, table)\n",
    "            mark_manifest(\n",
    "                cur,\n",
    "                file_hash,\n",
    "                status=\"LOADED\",\n",
    "                rows_loaded=len(df),\n",
    "                error_message=None,\n",
    "            )\n",
    "            print(f\"Loaded {len(df)} rows from {f} into {table}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # COPY or any SQL error aborts the transaction → must rollback first\n",
    "            cur.connection.rollback()\n",
    "\n",
    "            mark_manifest(\n",
    "                cur,\n",
    "                file_hash,\n",
    "                status=\"FAILED\",\n",
    "                rows_loaded=None,\n",
    "                error_message=str(e),\n",
    "            )\n",
    "            raise\n",
    "# for f in glob.glob(\"./data/input/cicli/*/*_attivita_formative_interne.csv\"):\n",
    "#     print(extract_matricola_from_filename(f))\n",
    "#     print(extract_ciclo_from_path(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817c683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
